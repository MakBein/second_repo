# xss_security_gui/auto_recon/scanner.py
# === –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ ===
import os
import re
import json
import threading
import datetime
import logging
from urllib.parse import urljoin
from typing import Optional, List, Dict, Any

# === –í–Ω–µ—à–Ω–∏–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ ===
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from bs4 import BeautifulSoup

# === –õ–æ–∫–∞–ª—å–Ω—ã–µ —É—Ç–∏–ª–∏—Ç—ã ===
from xss_security_gui.utils.core_utils import normalize_url

# === –õ–æ–∫–∞–ª—å–Ω—ã–µ –º–æ–¥—É–ª–∏ ===
from xss_security_gui.xss_detector import XSSDetector
from xss_security_gui.threat_analysis.threat_connector import THREAT_CONNECTOR


# =======================
# –£—Å—Ç–æ–π—á–∏–≤—ã–π HTTP-—Å–µ—Å—Å–∏—è
# =======================
def create_retry_session(
    total: int = 3,
    backoff_factor: float = 0.5,
    status_forcelist: tuple = (429, 500, 502, 503, 504),
) -> requests.Session:
    """
    –°–æ–∑–¥–∞—ë—Ç HTTP-—Å–µ—Å—Å–∏—é —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –ø–æ–≤—Ç–æ—Ä–æ–º –∑–∞–ø—Ä–æ—Å–æ–≤.
    ‚Ä¢ total: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫
    ‚Ä¢ backoff_factor: –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –ø–æ–ø—ã—Ç–∫–∞–º–∏
    ‚Ä¢ status_forcelist: —Å–ø–∏—Å–æ–∫ –∫–æ–¥–æ–≤ –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫
    """
    retry = Retry(
        total=total,
        connect=total,
        read=total,
        status=total,
        backoff_factor=backoff_factor,
        status_forcelist=status_forcelist,
        allowed_methods=frozenset(
            ["GET", "POST", "PUT", "DELETE", "HEAD", "OPTIONS", "TRACE", "PATCH"]
        ),
        raise_on_status=False,
        respect_retry_after_header=True,
    )

    adapter = HTTPAdapter(max_retries=retry)
    session = requests.Session()
    session.mount("http://", adapter)
    session.mount("https://", adapter)
    return session


# =======================
# –û—Å–Ω–æ–≤–Ω–æ–π —Å–∫–∞–Ω–µ—Ä
# =======================
class EndpointScanner:
    """
    AutoRecon Enterprise 2.0 EndpointScanner
    ‚Ä¢ –°–∫–∞–Ω–∏—Ä—É–µ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã, —Ñ–æ—Ä–º—ã, JS –∏ XHR
    ‚Ä¢ –ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç—Å—è —Å ThreatConnector
    ‚Ä¢ –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç XSS-—Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ
    """

    def __init__(self, target_url: str, gui_callback=None):
        self.session = create_retry_session()
        self.target = target_url.rstrip("/")
        self.headers = {"User-Agent": "AutoReconScanner/2.0"}
        self.endpoints: list[dict] = []
        self.gui_callback = gui_callback
        self.detector = XSSDetector()

    # -----------------------
    # –û—Å–Ω–æ–≤–Ω–æ–π —Å–±–æ—Ä —ç–Ω–¥–ø–æ–∏–Ω—Ç–æ–≤
    # -----------------------
    def scan(self) -> list[dict]:
        try:
            response = self.session.get(self.target, headers=self.headers, timeout=10)
            response.raise_for_status()
        except requests.exceptions.RequestException as e:
            self._report_gui({"error": f"Failed to fetch target: {e}"})
            return []

        soup = BeautifulSoup(response.text, "html.parser")

        forms = self.extract_forms(soup)
        js_links = self.extract_js_links(soup)
        apis = self.extract_xhr(js_links)

        root_entry = {
            "url": self.target,
            "method": "GET",
            "params": {},
            "source": "root",
            "status": response.status_code,
            "headers": dict(response.request.headers),
            "response_headers": dict(response.headers),
            "full_response": response.text[:2000],  # –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
            "timestamp": datetime.datetime.utcnow().isoformat()
        }

        self.endpoints = [root_entry] + forms + apis
        self._report_gui({"info": f"Discovered {len(self.endpoints)} endpoints"})

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –≤ ThreatConnector
        THREAT_CONNECTOR.add_artifact("EndpointScanner", self.target, self.endpoints)

        return self.endpoints

    # -----------------------
    # –§–æ—Ä–º—ã
    # -----------------------
    def extract_forms(self, soup: BeautifulSoup) -> list[dict]:
        result = []
        for form in soup.find_all("form"):
            action = urljoin(self.target, form.get("action", ""))
            method = form.get("method", "GET").upper()

            params = {
                inp.get("name"): ""
                for inp in form.find_all("input")
                if inp.get("name")
            }

            result.append({
                "url": action,
                "method": method,
                "params": params,
                "source": "form",
                "status": None,
                "headers": dict(self.headers),
                "response_headers": {},
                "timestamp": datetime.datetime.utcnow().isoformat()
            })
        return result

    # -----------------------
    # JS-—Ñ–∞–π–ª—ã
    # -----------------------
    def extract_js_links(self, soup: BeautifulSoup) -> list[str]:
        return [urljoin(self.target, s["src"]) for s in soup.find_all("script", src=True)]

    # -----------------------
    # XHR / fetch / ajax
    # -----------------------
    def extract_xhr(self, js_links: list[str]) -> list[dict]:
        api_patterns = []
        xhr_regex = re.compile(
            r"(fetch|xhr|ajax)\s*\(\s*['\"]([^'\"]+)['\"]",
            re.IGNORECASE
        )

        for js_url in js_links:
            try:
                resp = self.session.get(js_url, headers=self.headers, timeout=10)
                js_text = resp.text
                found = xhr_regex.findall(js_text)

                for _, url in found:
                    full_url = urljoin(self.target, url)
                    api_patterns.append({
                        "url": full_url,
                        "method": "POST",
                        "params": {"key": ""},
                        "source": "js",
                        "status": resp.status_code,
                        "headers": dict(resp.request.headers),
                        "response_headers": dict(resp.headers),
                        "timestamp": datetime.datetime.utcnow().isoformat()
                    })
            except requests.exceptions.RequestException as e:
                self._report_gui({"warning": f"Failed to fetch JS {js_url}: {e}"})
                continue

        return api_patterns

    # -----------------------
    # XSS-—Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —ç–Ω–¥–ø–æ–∏–Ω—Ç–æ–≤
    # -----------------------
    def scan_xss_on_endpoints(self, payload: str = '<img src=x onerror=alert(1)>') -> list[dict]:
        results = []
        for ep in self.endpoints:
            if ep["method"] != "GET":
                continue

            try:
                full_url = normalize_url(self.target, ep["url"])
                response = self.session.get(
                    full_url,
                    params=ep.get("params", {}),
                    headers=self.headers,
                    timeout=10
                )
                html = response.text
                reflected = payload in html

                if reflected:
                    context = self.detector.detect_xss_context(html, payload)
                    js_hits = self.detector.scan_inline_js_for_payload(html, payload)
                else:
                    context, js_hits = "‚ùå Not reflected", []

                result = {
                    "url": response.url,
                    "request_url": response.url,
                    "status": response.status_code,
                    "method": ep.get("method", "GET"),
                    "payload": payload,
                    "context": context or "‚ùì Unknown",
                    "category": context if reflected else "none",
                    "js_hits": js_hits,
                    "source": ep.get("source", "unknown"),
                    "full_response": html[:2000],
                    "headers": dict(response.request.headers),
                    "response_headers": dict(response.headers),
                    "timestamp": datetime.datetime.utcnow().isoformat(),
                    "vulnerable": reflected
                }

                results.append(result)
                self._report_gui(result)
                THREAT_CONNECTOR.add_artifact("XSSScanner", response.url, [result])

            except requests.exceptions.RequestException as e:
                error_result = {
                    "url": ep["url"],
                    "error": str(e),
                    "source": ep.get("source", "unknown"),
                    "timestamp": datetime.datetime.utcnow().isoformat()
                }
                results.append(error_result)
                self._report_gui(error_result)

        return results

    # -----------------------
    # XSS fuzzing –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    # -----------------------
    def fuzz_xss_parameters(self, base_params=None, method="GET"):
        """
        –§—É–∑–∑–∏–Ω–≥ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è XSS.
        ‚Ä¢ base_params: —Å–ª–æ–≤–∞—Ä—å –±–∞–∑–æ–≤—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        ‚Ä¢ method: HTTP –º–µ—Ç–æ–¥ (GET/POST)
        """
        results = []
        generated = self.detector.fuzz_xss_parameters(self.target, base_params or {}, method)

        for payload_entry in generated:
            try:
                if method.upper() == "GET" and isinstance(payload_entry, str):
                    full_url = normalize_url(self.target, payload_entry)
                    response = self.session.get(full_url, headers=self.headers, timeout=10)

                elif isinstance(payload_entry, dict):
                    url = normalize_url(self.target, payload_entry.get("url", self.target))
                    response = self.session.post(
                        url,
                        json=payload_entry.get("json", {}),
                        headers=self.headers,
                        timeout=10
                    )
                else:
                    continue

                html = response.text
                payload_str = payload_entry if isinstance(payload_entry, str) else str(payload_entry.get("json", {}))
                reflected = payload_str in html

                if reflected:
                    context = self.detector.detect_xss_context(html, payload_str)
                    js_hits = self.detector.scan_inline_js_for_payload(html, payload_str)
                else:
                    context, js_hits = "‚ùå Not reflected", []

                result = {
                    "module": "XSSFuzzer",
                    "url": getattr(response, "url", payload_entry),
                    "request_url": getattr(response, "url", payload_entry),
                    "status": response.status_code,
                    "method": method,
                    "payload": payload_str,
                    "context": context or "‚ùì Unknown",
                    "category": context if reflected else "none",
                    "js_hits": js_hits,
                    "source": "xss_fuzzer",
                    "full_response": html[:2000],
                    "headers": dict(response.request.headers),
                    "response_headers": dict(response.headers),
                    "response_length": len(html),
                    "timestamp": datetime.datetime.utcnow().isoformat(),
                    "vulnerable": reflected,
                    "severity": "high" if reflected else "info"
                }

                results.append(result)
                self._report_gui(result)
                THREAT_CONNECTOR.add_artifact("XSSFuzzer", result["url"], [result])

            except requests.exceptions.RequestException as e:
                error_result = {
                    "module": "XSSFuzzer",
                    "url": payload_entry if isinstance(payload_entry, str) else payload_entry.get("url", self.target),
                    "error": str(e),
                    "source": "xss_fuzzer",
                    "timestamp": datetime.datetime.utcnow().isoformat(),
                    "severity": "error",
                    "vulnerable": False
                }
                results.append(error_result)
                self._report_gui(error_result)
                THREAT_CONNECTOR.add_artifact("XSSFuzzer", error_result["url"], [error_result])

        return results

    # -----------------------
    # GUI callback
    # -----------------------
    def _report_gui(self, data: dict):
        """
        –û—Ç–ø—Ä–∞–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤ GUI —Å –±–µ–∑–æ–ø–∞—Å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π.
        ‚Ä¢ data: —Å–ª–æ–≤–∞—Ä—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∏–ª–∏ –æ—à–∏–±–∫–∏
        """
        data.setdefault("timestamp", datetime.datetime.utcnow().isoformat())
        wrapped = {"scanner": data}

        # –õ–æ–≥–∏—Ä—É–µ–º
        if "error" in data:
            logging.error(f"[GUI] {data.get('error')}")
        elif data.get("vulnerable"):
            logging.info(f"[GUI] XSS –Ω–∞–π–¥–µ–Ω: {data.get('url')} payload={data.get('payload')}")
        else:
            logging.info(f"[GUI] {data.get('url')} ‚Üí {data.get('status')}")

        if self.gui_callback:
            try:
                self.gui_callback(wrapped)
            except Exception as e:
                logging.warning(f"[GUI] –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ callback: {e}")


# =======================
# –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
# =======================

def extract_context(payload: str, html: str, context: int = 50) -> Optional[tuple[str, int]]:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤–æ–∫—Ä—É–≥ –æ—Ç—Ä–∞–∂—ë–Ω–Ω–æ–≥–æ payload –≤ HTML.
    ‚Ä¢ payload: —Å—Ç—Ä–æ–∫–∞, –∫–æ—Ç–æ—Ä—É—é –∏—â–µ–º
    ‚Ä¢ html: HTML-–∫–æ–¥ –æ—Ç–≤–µ—Ç–∞
    ‚Ä¢ context: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–º–≤–æ–ª–æ–≤ –≤–æ–∫—Ä—É–≥ payload
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (—Ñ—Ä–∞–≥–º–µ–Ω—Ç, –∏–Ω–¥–µ–∫—Å) –∏–ª–∏ None.
    """
    if not payload or not html:
        return None

    index = html.find(payload)
    if index == -1:
        return None

    start = max(0, index - context)
    end = min(len(html), index + len(payload) + context)

    snippet = html[start:end]
    return snippet, index


def categorize_reflection(payload: str, html: str) -> str:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏—é –æ—Ç—Ä–∞–∂–µ–Ω–∏—è payload –≤ HTML.
    ‚Ä¢ payload: —Å—Ç—Ä–æ–∫–∞, –∫–æ—Ç–æ—Ä—É—é –∏—â–µ–º
    ‚Ä¢ html: HTML-–∫–æ–¥ –æ—Ç–≤–µ—Ç–∞
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏—é: HTML, JS, Attribute Injection, raw –∏–ª–∏ unknown.
    """
    snippet, _ = extract_context(payload, html, context=100) or (None, None)
    if not snippet:
        return "unknown"

    if re.search(r"<[^>]+{}[^>]*>".format(re.escape(payload)), snippet):
        return "üî§ Reflected HTML"

    if re.search(r'["\']{}["\']'.format(re.escape(payload)), snippet):
        return "üìú Reflected JS"

    if re.search(r'\s+\w+=["\']{}["\']'.format(re.escape(payload)), snippet):
        return "üß¨ Attribute Injection"

    return "raw"


def suggest_payload_by_category(category: str) -> str:
    """
    –ü—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏–π payload –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –æ—Ç—Ä–∞–∂–µ–Ω–∏—è.
    ‚Ä¢ category: —Å—Ç—Ä–æ–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä–æ–∫—É payload.
    """
    mapping = {
        "üî§ Reflected HTML": "<script>alert(1)</script>",
        "üß¨ Attribute Injection": '" onerror="alert(1)',
        "üìú Reflected JS": '";alert(1)//',
        "raw": "<img src=x onerror=alert(1)>"
    }
    return mapping.get(category, "<img src=x onerror=alert(1)>")


def scan_url(url: str) -> dict:
    """
    –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Å–∫–∞–Ω–µ—Ä –æ–¥–Ω–æ–≥–æ URL.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É, —Å–æ–≤–º–µ—Å—Ç–∏–º—É—é —Å AutoReconAnalyzerV2.
    """
    try:
        import requests
        r = requests.get(url, timeout=5)
        return {
            "module": "URLScanner",
            "url": url,
            "text": r.text[:2000],  # –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
            "headers": dict(r.headers),
            "status": r.status_code,
            "source": "scan_url",
            "timestamp": datetime.datetime.utcnow().isoformat()
        }
    except Exception as e:
        return {
            "module": "URLScanner",
            "url": url,
            "text": "",
            "headers": {},
            "status": "error",
            "error": str(e),
            "source": "scan_url",
            "timestamp": datetime.datetime.utcnow().isoformat()
        }


def scan_multiple(urls: list[str]) -> list[dict]:
    """
    –°–∫–∞–Ω–∏—Ä—É–µ—Ç —Å–ø–∏—Å–æ–∫ URL –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ responses.
    ‚Ä¢ urls: —Å–ø–∏—Å–æ–∫ URL
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä—É–∫—Ç—É—Ä.
    """
    results = []
    for u in urls:
        result = scan_url(u)
        results.append(result)
    return results


# =======================
# NDJSON –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ XSS
# =======================

LOG_DIR = "logs/xss"
LOG_FILE = os.path.join(LOG_DIR, "reflected_responses.json")

_write_lock = threading.Lock()


def rotate_if_big(path: str, max_mb: int = 20) -> None:
    """
    –†–æ—Ç–∞—Ü–∏—è –ª–æ–≥–æ–≤, –µ—Å–ª–∏ —Ñ–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π.
    ‚Ä¢ path: –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É
    ‚Ä¢ max_mb: –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –≤ –º–µ–≥–∞–±–∞–π—Ç–∞—Ö
    """
    try:
        if os.path.exists(path) and os.path.getsize(path) > max_mb * 1024 * 1024:
            ts = datetime.datetime.utcnow().strftime("%Y%m%d_%H%M%S")
            backup = f"{path}.{ts}.bak"
            os.rename(path, backup)
            logging.info(f"[NDJSON] –õ–æ–≥ {path} —Ä–æ—Ç–∏—Ä–æ–≤–∞–Ω ‚Üí {backup}")
    except Exception as e:
        logging.error(f"[NDJSON] –û—à–∏–±–∫–∞ —Ä–æ—Ç–∞—Ü–∏–∏: {e}")


def validate_result(result: Dict[str, Any]) -> bool:
    """
    –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞.
    ‚Ä¢ result: —Å–ª–æ–≤–∞—Ä—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    """
    required = {"url", "category", "context"}
    missing = required - result.keys()
    if missing:
        logging.warning(f"[NDJSON] –ü—Ä–æ–ø—É—â–µ–Ω—ã –ø–æ–ª—è: {missing}")
        return False
    return True


def save_reflected_response(result: Dict[str, Any]) -> None:
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç XSS-–æ—Ç—Ä–∞–∂–µ–Ω–∏–µ –≤ NDJSON —Ñ–æ—Ä–º–∞—Ç–µ.
    ‚Ä¢ result: —Å–ª–æ–≤–∞—Ä—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    """
    try:
        os.makedirs(LOG_DIR, exist_ok=True)
        result.setdefault("_ts", datetime.datetime.utcnow().isoformat())

        if not validate_result(result):
            return

        rotate_if_big(LOG_FILE)

        with _write_lock:
            with open(LOG_FILE, "a", encoding="utf-8") as f:
                f.write(json.dumps(result, ensure_ascii=False) + "\n")

        logging.info(f"[NDJSON] –ê—Ä—Ç–µ—Ñ–∞–∫—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {result.get('url')} [{result.get('category')}]")

    except Exception as e:
        logging.error(f"[NDJSON] –û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏: {e}")


def load_reflected_responses(path: str = LOG_FILE) -> List[Dict[str, Any]]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç NDJSON —Ñ–∞–π–ª –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π.
    ‚Ä¢ path: –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É
    """
    results: List[Dict[str, Any]] = []
    if not os.path.exists(path):
        logging.warning(f"[NDJSON] –§–∞–π–ª {path} –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        return results

    try:
        with open(path, encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                try:
                    results.append(json.loads(line))
                except json.JSONDecodeError as e:
                    logging.warning(f"[NDJSON] –û—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è —Å—Ç—Ä–æ–∫–∏: {e}")
    except Exception as e:
        logging.error(f"[NDJSON] –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {path}: {e}")

    logging.info(f"[NDJSON] –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(results)} –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –∏–∑ {path}")
    return results


if __name__ == "__main__":
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s [%(levelname)s] %(message)s",
        handlers=[
            logging.FileHandler("logs/xss_ndjson.log", encoding="utf-8"),
            logging.StreamHandler()
        ]
    )

    responses = load_reflected_responses()
    print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(responses)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
    for r in responses[:3]:
        print(r.get("url"), r.get("category"), r.get("context"))
