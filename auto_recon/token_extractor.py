# xss_security_gui/auto_recon/token_extractor.py
"""
Token Extractor ULTRA 6.5
-------------------------
â€¢ Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµÑ‚ Ñ‚Ğ¾ĞºĞµĞ½Ñ‹ Ğ¸Ğ· Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ¾Ğ² Ğ¸ HTML
â€¢ ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ JWT Ğ¸ CSRF
â€¢ ĞÑ†ĞµĞ½Ğ¸Ğ²Ğ°ĞµÑ‚ Ñ€Ğ¸ÑĞºĞ¸
â€¢ Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµÑ‚ Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚ Ğ² JSON
â€¢ ĞŸĞ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµÑ‚ CLI Ğ¸ GUI Ñ€ĞµĞ¶Ğ¸Ğ¼Ñ‹
"""

import re
import json
import logging
import threading
from pathlib import Path
from typing import List, Dict, Any

from xss_security_gui.utils.jwt_decoder import decode_jwt, assess_risks
from xss_security_gui.config_manager import LOGS_DIR

# ğŸ“ Ğ£Ğ½Ğ¸Ğ²ĞµÑ€ÑĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿ÑƒÑ‚ÑŒ Ğº Ğ»Ğ¾Ğ³Ğ°Ğ¼
LOG_DIR: Path = LOGS_DIR / "tokens"
LOG_FILE: Path = LOG_DIR / "token_risks.json"
LOG_DIR.mkdir(parents=True, exist_ok=True)


def extract_tokens(headers: Dict[str, str], html: str) -> List[Dict[str, str]]:
    """Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµÑ‚ Ñ‚Ğ¾ĞºĞµĞ½Ñ‹ Ğ¸Ğ· Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ¾Ğ² Ğ¸ HTML."""
    tokens: List[Dict[str, str]] = []
    try:
        for k, v in headers.items():
            if "token" in k.lower() or "authorization" in k.lower():
                tokens.append({"source": k, "value": v})

        csrf_matches = re.findall(r'name=["\']csrf["\'].*?value=["\'](.*?)["\']', html, re.I)
        for match in csrf_matches:
            tokens.append({"source": "CSRF Hidden Field", "value": match})

        storage_matches = re.findall(r'localStorage\.setItem\(["\'](\w+)["\']\s*,\s*["\'](.*?)["\']\)', html)
        for key, val in storage_matches:
            tokens.append({"source": f"localStorage:{key}", "value": val})
    except Exception as e:
        logging.error(f"[TokenExtractor] ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ñ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²: {e}", exc_info=True)

    return tokens


def analyze_tokens(tokens: List[Dict[str, str]], expected_aud: str = "expected-aud") -> List[Dict[str, Any]]:
    """ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ñ‚Ğ¾ĞºĞµĞ½Ñ‹, Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµÑ‚ Ñ‚Ğ¸Ğ¿ Ğ¸ Ñ€Ğ¸ÑĞºĞ¸."""
    analyzed: List[Dict[str, Any]] = []
    for t in tokens:
        result: Dict[str, Any] = {
            "source": t.get("source"),
            "value": t.get("value"),
            "type": "opaque",
            "risks": [],
            "risk_level": "low",
        }

        decoded = decode_jwt(t["value"])
        if decoded:
            result["type"] = "JWT"
            result["decoded"] = decoded
            result["risks"] = assess_risks(decoded, expected_aud)

            if "ğŸ“› ĞĞ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼ Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑĞ¸: none" in result["risks"]:
                result["risk_level"] = "high"
            elif len(result["risks"]) >= 2:
                result["risk_level"] = "medium"
            else:
                result["risk_level"] = "low"

        analyzed.append(result)
    return analyzed


def save_token_log(analyzed: List[Dict[str, Any]], path: Path = LOG_FILE) -> None:
    """Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµÑ‚ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ² Ğ² JSON."""
    try:
        path.parent.mkdir(parents=True, exist_ok=True)
        with path.open("w", encoding="utf-8") as f:
            json.dump(analyzed, f, indent=2, ensure_ascii=False)
        logging.info(f"[TokenExtractor] Ğ›Ğ¾Ğ³ ÑĞ¾Ñ…Ñ€Ğ°Ğ½Ñ‘Ğ½: {path}")
    except Exception as e:
        logging.error(f"[TokenExtractor] ĞÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°Ğ¿Ğ¸ÑĞ¸ Ğ»Ğ¾Ğ³Ğ°: {e}", exc_info=True)


def _process_tokens(headers: Dict[str, str], html: str, output_path: Path = LOG_FILE) -> List[Dict[str, Any]]:
    """ĞĞ±Ñ‰Ğ°Ñ Ğ»Ğ¾Ğ³Ğ¸ĞºĞ° Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ñ, Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²."""
    tokens = extract_tokens(headers, html)
    analyzed = analyze_tokens(tokens)
    save_token_log(analyzed, output_path)
    return analyzed


# ğŸ“¦ CLI-Ñ€ĞµĞ¶Ğ¸Ğ¼
def run_from_cli(headers_path: Path, html_path: Path, output_path: Path = LOG_FILE) -> None:
    try:
        with headers_path.open(encoding="utf-8") as f:
            headers = json.load(f)
        with html_path.open(encoding="utf-8") as f:
            html = f.read()
    except Exception as e:
        print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ğ²Ñ…Ğ¾Ğ´Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…: {e}")
        return

    analyzed = _process_tokens(headers, html, output_path)
    print(f"âœ… ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ·Ğ°Ğ²ĞµÑ€ÑˆÑ‘Ğ½. Ğ›Ğ¾Ğ³ ÑĞ¾Ñ…Ñ€Ğ°Ğ½Ñ‘Ğ½ Ğ²: {output_path}")


# ğŸ”§ GUI-Ñ€ĞµĞ¶Ğ¸Ğ¼ (Ğ°ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ğ·Ğ°Ğ¿ÑƒÑĞº)
def analyze_from_gui(headers: Dict[str, str], html: str, output_path: Path = LOG_FILE, callback=None) -> None:
    """Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°ĞµÑ‚ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ² Ğ² Ñ„Ğ¾Ğ½Ğµ, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ½Ğµ Ğ±Ğ»Ğ¾ĞºĞ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ GUI."""
    def worker():
        analyzed = _process_tokens(headers, html, output_path)
        if callback:
            try:
                callback(analyzed)
            except Exception as e:
                logging.error(f"[TokenExtractor] ĞÑˆĞ¸Ğ±ĞºĞ° Ğ² GUI callback: {e}", exc_info=True)

    threading.Thread(target=worker, daemon=True).start()


# ğŸš€ ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ²Ñ‹Ğ±Ğ¾Ñ€ Ñ€ĞµĞ¶Ğ¸Ğ¼Ğ°
if __name__ == "__main__":
    import sys

    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s [%(levelname)s] %(message)s",
        handlers=[
            logging.FileHandler(LOG_DIR / "token_extractor.log", encoding="utf-8"),
            logging.StreamHandler(),
        ],
    )

    if len(sys.argv) >= 3:
        headers_file = Path(sys.argv[1])
        html_file = Path(sys.argv[2])
        output_file = Path(sys.argv[3]) if len(sys.argv) > 3 else LOG_FILE
        run_from_cli(headers_file, html_file, output_file)
    else:
        print("ğŸ“˜ Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ:")
        print("  python -m xss_security_gui.auto_recon.token_extractor headers.json response.html [output.json]")