# xss_security_gui/auto_recon/scanner.py

# === –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ ===
from pathlib import Path
import datetime
import json
import logging
import re
import threading
from typing import Optional, List, Dict, Any
from urllib.parse import urljoin

# === –í–Ω–µ—à–Ω–∏–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ ===
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from bs4 import BeautifulSoup

# === –õ–æ–∫–∞–ª—å–Ω—ã–µ —É—Ç–∏–ª–∏—Ç—ã ===
from xss_security_gui.utils.core_utils import normalize_url
from xss_security_gui.config_manager import LOGS_DIR

# === –õ–æ–∫–∞–ª—å–Ω—ã–µ –º–æ–¥—É–ª–∏ ===
from xss_security_gui.xss_detector import XSSDetector
from xss_security_gui.threat_analysis.threat_connector import THREAT_CONNECTOR


# ============================================================
#  –£—Å—Ç–æ–π—á–∏–≤—ã–π HTTP-—Å–µ—Å—Å–∏—è
# ============================================================

def create_retry_session(
    total: int = 3,
    backoff_factor: float = 0.5,
    status_forcelist: tuple = (429, 500, 502, 503, 504),
) -> requests.Session:
    """
    –°–æ–∑–¥–∞—ë—Ç HTTP-—Å–µ—Å—Å–∏—é —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –ø–æ–≤—Ç–æ—Ä–æ–º –∑–∞–ø—Ä–æ—Å–æ–≤.

    Args:
        total: –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫.
        backoff_factor: –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –ø–æ–ø—ã—Ç–∫–∞–º–∏.
        status_forcelist: –∫–æ–¥—ã –æ—Ç–≤–µ—Ç–æ–≤, –ø—Ä–∏ –∫–æ—Ç–æ—Ä—ã—Ö –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –ø–æ–≤—Ç–æ—Ä.
    """
    retry = Retry(
        total=total,
        connect=total,
        read=total,
        status=total,
        backoff_factor=backoff_factor,
        status_forcelist=status_forcelist,
        allowed_methods=frozenset(
            ["GET", "POST", "PUT", "DELETE", "HEAD", "OPTIONS", "TRACE", "PATCH"]
        ),
        raise_on_status=False,
        respect_retry_after_header=True,
    )

    adapter = HTTPAdapter(max_retries=retry)
    session = requests.Session()
    session.mount("http://", adapter)
    session.mount("https://", adapter)
    return session


# ============================================================
#  –û—Å–Ω–æ–≤–Ω–æ–π —Å–∫–∞–Ω–µ—Ä —ç–Ω–¥–ø–æ–∏–Ω—Ç–æ–≤
# ============================================================

class EndpointScanner:
    """
    AutoRecon EndpointScanner 2.0

    ‚Ä¢ –°–∫–∞–Ω–∏—Ä—É–µ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã, —Ñ–æ—Ä–º—ã, JS –∏ XHR
    ‚Ä¢ –ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç—Å—è —Å ThreatConnector
    ‚Ä¢ –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç XSS-—Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ
    """

    def __init__(self, target_url: str, gui_callback: Optional[callable] = None):
        self.session = create_retry_session()
        self.target = target_url.rstrip("/")
        self.headers = {"User-Agent": "AutoReconScanner/2.0"}
        self.endpoints: List[Dict[str, Any]] = []
        self.gui_callback = gui_callback
        self.detector = XSSDetector()

    # --------------------------------------------------------
    # –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–π –º–µ—Ç–æ–¥: –æ—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–±—ã—Ç–∏–π –≤ GUI
    # --------------------------------------------------------

    def _report_gui(self, message: Dict[str, Any]):
        if self.gui_callback:
            try:
                self.gui_callback(message)
            except Exception as e:
                logging.error(f"[EndpointScanner] GUI callback error: {e}", exc_info=True)

    # --------------------------------------------------------
    # –û—Å–Ω–æ–≤–Ω–æ–π —Å–±–æ—Ä —ç–Ω–¥–ø–æ–∏–Ω—Ç–æ–≤
    # --------------------------------------------------------

    def scan(self) -> List[Dict[str, Any]]:
        """–°–∫–∞–Ω–∏—Ä—É–µ—Ç —Ü–µ–ª–µ–≤—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Ñ–æ—Ä–º—ã, JS –∏ XHR."""
        try:
            response = self.session.get(self.target, headers=self.headers, timeout=10)
            response.raise_for_status()
        except requests.exceptions.RequestException as e:
            self._report_gui({"error": f"Failed to fetch target: {e}"})
            logging.error(f"[EndpointScanner] Failed to fetch target {self.target}: {e}")
            return []

        soup = BeautifulSoup(response.text, "html.parser")

        forms = self.extract_forms(soup)
        js_links = self.extract_js_links(soup)
        apis = self.extract_xhr(js_links)

        root_entry: Dict[str, Any] = {
            "url": self.target,
            "method": "GET",
            "params": {},
            "source": "root",
            "status": response.status_code,
            "headers": dict(response.request.headers),
            "response_headers": dict(response.headers),
            "full_response": response.text[:2000],
            "timestamp": datetime.datetime.utcnow().isoformat(),
        }

        self.endpoints = [root_entry] + forms + apis
        self._report_gui({"info": f"Discovered {len(self.endpoints)} endpoints"})

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –≤ ThreatConnector
        try:
            THREAT_CONNECTOR.add_artifact("EndpointScanner", self.target, self.endpoints)
        except Exception as e:
            logging.error(f"[EndpointScanner] ThreatConnector error: {e}", exc_info=True)

        return self.endpoints

    # --------------------------------------------------------
    # –§–æ—Ä–º—ã
    # --------------------------------------------------------

    def extract_forms(self, soup: BeautifulSoup) -> List[Dict[str, Any]]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç HTML-—Ñ–æ—Ä–º—ã –∏ –ø—Ä–µ–≤—Ä–∞—â–∞–µ—Ç –∏—Ö –≤ —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã."""
        result: List[Dict[str, Any]] = []

        for form in soup.find_all("form"):
            action = urljoin(self.target, form.get("action", ""))
            method = form.get("method", "GET").upper()

            params = {
                inp.get("name"): ""
                for inp in form.find_all("input")
                if inp.get("name")
            }

            result.append({
                "url": action,
                "method": method,
                "params": params,
                "source": "form",
                "status": None,
                "headers": dict(self.headers),
                "response_headers": {},
                "timestamp": datetime.datetime.utcnow().isoformat(),
            })

        return result

    # --------------------------------------------------------
    # JS-—Ñ–∞–π–ª—ã
    # --------------------------------------------------------

    def extract_js_links(self, soup: BeautifulSoup) -> List[str]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∞–±—Å–æ–ª—é—Ç–Ω—ã—Ö —Å—Å—ã–ª–æ–∫ –Ω–∞ JS-—Ñ–∞–π–ª—ã."""
        return [
            urljoin(self.target, s["src"])
            for s in soup.find_all("script", src=True)
        ]

    # --------------------------------------------------------
    # XHR / fetch / ajax
    # --------------------------------------------------------

    def extract_xhr(self, js_links: List[str]) -> List[Dict[str, Any]]:
        """
        –ò—â–µ—Ç –≤ JS-—Ñ–∞–π–ª–∞—Ö –≤—ã–∑–æ–≤—ã fetch/xhr/ajax –∏ —Å—Ç—Ä–æ–∏—Ç —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã.
        """
        api_patterns: List[Dict[str, Any]] = []
        xhr_regex = re.compile(
            r"(fetch|xhr|ajax)\s*\(\s*['\"]([^'\"]+)['\"]",
            re.IGNORECASE,
        )

        for js_url in js_links:
            try:
                resp = self.session.get(js_url, headers=self.headers, timeout=10)
                js_text = resp.text
                found = xhr_regex.findall(js_text)

                for _, url in found:
                    full_url = urljoin(self.target, url)
                    api_patterns.append({
                        "url": full_url,
                        "method": "POST",
                        "params": {"key": ""},
                        "source": "js",
                        "status": resp.status_code,
                        "headers": dict(resp.request.headers),
                        "response_headers": dict(resp.headers),
                        "timestamp": datetime.datetime.utcnow().isoformat(),
                    })

            except requests.exceptions.RequestException as e:
                self._report_gui({"warning": f"Failed to fetch JS {js_url}: {e}"})
                logging.warning(f"[EndpointScanner] Failed to fetch JS {js_url}: {e}")

        return api_patterns

    # --------------------------------------------------------
    # XSS-—Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —ç–Ω–¥–ø–æ–∏–Ω—Ç–æ–≤
    # --------------------------------------------------------

    def scan_xss_on_endpoints(
        self,
        payload: str = "<img src=x onerror=alert(1)>",
    ) -> List[Dict[str, Any]]:
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø—Ä–æ—Å—Ç–æ–µ XSS-—Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ –≤—Å–µ–º GET-—ç–Ω–¥–ø–æ–∏–Ω—Ç–∞–º.
        """
        results: List[Dict[str, Any]] = []

        for ep in self.endpoints:
            if ep.get("method", "GET").upper() != "GET":
                continue

            try:
                full_url = normalize_url(self.target, ep["url"])
                response = self.session.get(
                    full_url,
                    params=ep.get("params", {}),
                    headers=self.headers,
                    timeout=10,
                )
                html = response.text
                reflected = payload in html

                if reflected:
                    context = self.detector.detect_xss_context(html, payload)
                    js_hits = self.detector.scan_inline_js_for_payload(html, payload)
                else:
                    context, js_hits = "‚ùå Not reflected", []

                result: Dict[str, Any] = {
                    "url": response.url,
                    "request_url": response.url,
                    "status": response.status_code,
                    "method": ep.get("method", "GET"),
                    "payload": payload,
                    "context": context or "‚ùì Unknown",
                    "category": context if reflected else "none",
                    "js_hits": js_hits,
                    "source": ep.get("source", "unknown"),
                    "full_response": html[:2000],
                    "headers": dict(response.request.headers),
                    "response_headers": dict(response.headers),
                    "timestamp": datetime.datetime.utcnow().isoformat(),
                    "vulnerable": reflected,
                }

                results.append(result)
                self._report_gui(result)

                try:
                    THREAT_CONNECTOR.add_artifact("XSSScanner", response.url, [result])
                except Exception as e:
                    logging.error(f"[EndpointScanner] ThreatConnector XSS error: {e}", exc_info=True)

            except requests.exceptions.RequestException as e:
                error_result = {
                    "url": ep.get("url"),
                    "error": str(e),
                    "source": ep.get("source", "unknown"),
                    "timestamp": datetime.datetime.utcnow().isoformat(),
                }
                results.append(error_result)
                self._report_gui(error_result)
                logging.error(f"[EndpointScanner] XSS scan error for {ep.get('url')}: {e}")

        return results

    def fuzz_xss_parameters(self, base_params: Optional[Dict[str, Any]] = None, method: str = "GET") -> List[Dict[str, Any]]:
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç XSS‚Äëfuzzing –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.

        Args:
            base_params: —Å–ª–æ–≤–∞—Ä—å –±–∞–∑–æ–≤—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            method: HTTP‚Äë–º–µ—Ç–æ–¥ (GET/POST)

        Returns:
            –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ fuzzing –≤ —Ñ–æ—Ä–º–∞—Ç–µ, —Å–æ–≤–º–µ—Å—Ç–∏–º–æ–º —Å AutoReconAnalyzerV2.
        """
        results: List[Dict[str, Any]] = []
        base_params = base_params or {}

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è payload‚Äë–æ–≤ —á–µ—Ä–µ–∑ XSSDetector
        generated = self.detector.fuzz_xss_parameters(
            self.target,
            base_params,
            method,
        )

        for entry in generated:
            try:
                # ------------------------------------------------------------
                # 1. –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∑–∞–ø—Ä–æ—Å–∞
                # ------------------------------------------------------------
                if method.upper() == "GET" and isinstance(entry, str):
                    full_url = normalize_url(self.target, entry)
                    response = self.session.get(
                        full_url,
                        headers=self.headers,
                        timeout=10,
                    )
                    payload_str = entry

                elif isinstance(entry, dict):
                    url = normalize_url(self.target, entry.get("url", self.target))
                    response = self.session.post(
                        url,
                        json=entry.get("json", {}),
                        headers=self.headers,
                        timeout=10,
                    )
                    payload_str = json.dumps(entry.get("json", {}), ensure_ascii=False)

                else:
                    continue

                html = response.text
                reflected = payload_str in html

                # ------------------------------------------------------------
                # 2. –ê–Ω–∞–ª–∏–∑ –æ—Ç—Ä–∞–∂–µ–Ω–∏—è
                # ------------------------------------------------------------
                if reflected:
                    context = self.detector.detect_xss_context(html, payload_str)
                    js_hits = self.detector.scan_inline_js_for_payload(html, payload_str)
                else:
                    context, js_hits = "‚ùå Not reflected", []

                # ------------------------------------------------------------
                # 3. –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                # ------------------------------------------------------------
                result = {
                    "module": "XSSFuzzer",
                    "url": response.url,
                    "request_url": response.url,
                    "status": response.status_code,
                    "method": method.upper(),
                    "payload": payload_str,
                    "context": context or "‚ùì Unknown",
                    "category": context if reflected else "none",
                    "js_hits": js_hits,
                    "source": "xss_fuzzer",
                    "full_response": html[:2000],
                    "headers": dict(response.request.headers),
                    "response_headers": dict(response.headers),
                    "response_length": len(html),
                    "timestamp": datetime.datetime.utcnow().isoformat(),
                    "vulnerable": reflected,
                    "severity": "high" if reflected else "info",
                }

                results.append(result)
                self._report_gui(result)

                try:
                    THREAT_CONNECTOR.add_artifact("XSSFuzzer", result["url"], [result])
                except Exception as e:
                    logging.error(f"[XSSFuzzer] ThreatConnector error: {e}", exc_info=True)

            except requests.exceptions.RequestException as e:
                # ------------------------------------------------------------
                # –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞
                # ------------------------------------------------------------
                error_result = {
                    "module": "XSSFuzzer",
                    "url": entry if isinstance(entry, str) else entry.get("url", self.target),
                    "error": str(e),
                    "source": "xss_fuzzer",
                    "timestamp": datetime.datetime.utcnow().isoformat(),
                    "severity": "error",
                    "vulnerable": False,
                }

                results.append(error_result)
                self._report_gui(error_result)

                try:
                    THREAT_CONNECTOR.add_artifact("XSSFuzzer", error_result["url"], [error_result])
                except Exception as e2:
                    logging.error(f"[XSSFuzzer] ThreatConnector error: {e2}", exc_info=True)

        return results

    # ============================================================
    #  GUI callback
    # ============================================================
    def _report_gui(self, data: Dict[str, Any]):
        """
        –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –æ—Ç–ø—Ä–∞–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤ GUI.

        Args:
            data: —Å–ª–æ–≤–∞—Ä—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∏–ª–∏ –æ—à–∏–±–∫–∏
        """
        data.setdefault("timestamp", datetime.datetime.utcnow().isoformat())
        wrapped = {"scanner": data}

        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
        if "error" in data:
            logging.error(f"[GUI] {data.get('error')}")
        elif data.get("vulnerable"):
            logging.info(f"[GUI] XSS –Ω–∞–π–¥–µ–Ω: {data.get('url')} payload={data.get('payload')}")
        else:
            logging.info(f"[GUI] {data.get('url')} ‚Üí {data.get('status')}")

        if self.gui_callback:
            try:
                self.gui_callback(wrapped)
            except Exception as e:
                logging.warning(f"[GUI] –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ callback: {e}")

# ============================================================
#  –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
# ============================================================

def extract_context(payload: str, html: str, context: int = 50) -> Optional[tuple[str, int]]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ñ—Ä–∞–≥–º–µ–Ω—Ç HTML –≤–æ–∫—Ä—É–≥ payload."""
    if not payload or not html:
        return None

    index = html.find(payload)
    if index == -1:
        return None

    start = max(0, index - context)
    end = min(len(html), index + len(payload) + context)
    return html[start:end], index


def categorize_reflection(payload: str, html: str) -> str:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏—é –æ—Ç—Ä–∞–∂–µ–Ω–∏—è payload."""
    snippet, _ = extract_context(payload, html, context=100) or (None, None)
    if not snippet:
        return "unknown"

    if re.search(r"<[^>]+{}[^>]*>".format(re.escape(payload)), snippet):
        return "üî§ Reflected HTML"

    if re.search(r'["\']{}["\']'.format(re.escape(payload)), snippet):
        return "üìú Reflected JS"

    if re.search(r'\s+\w+=["\']{}["\']'.format(re.escape(payload)), snippet):
        return "üß¨ Attribute Injection"

    return "raw"


def suggest_payload_by_category(category: str) -> str:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏–π payload –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –æ—Ç—Ä–∞–∂–µ–Ω–∏—è."""
    mapping = {
        "üî§ Reflected HTML": "<script>alert(1)</script>",
        "üß¨ Attribute Injection": '" onerror="alert(1)',
        "üìú Reflected JS": '";alert(1)//',
        "raw": "<img src=x onerror=alert(1)>",
    }
    return mapping.get(category, "<img src=x onerror=alert(1)>")


def scan_url(url: str) -> Dict[str, Any]:
    """–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Å–∫–∞–Ω–µ—Ä –æ–¥–Ω–æ–≥–æ URL."""
    try:
        r = requests.get(url, timeout=5)
        return {
            "module": "URLScanner",
            "url": url,
            "text": r.text[:2000],
            "headers": dict(r.headers),
            "status": r.status_code,
            "source": "scan_url",
            "timestamp": datetime.datetime.utcnow().isoformat(),
        }
    except Exception as e:
        return {
            "module": "URLScanner",
            "url": url,
            "text": "",
            "headers": {},
            "status": "error",
            "error": str(e),
            "source": "scan_url",
            "timestamp": datetime.datetime.utcnow().isoformat(),
        }


def scan_multiple(urls: List[str]) -> List[Dict[str, Any]]:
    """–°–∫–∞–Ω–∏—Ä—É–µ—Ç —Å–ø–∏—Å–æ–∫ URL –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä—É–∫—Ç—É—Ä."""
    return [scan_url(u) for u in urls]

# ============================================================
#  NDJSON –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ XSS
# ============================================================

LOG_DIR: Path = LOGS_DIR / "xss"
LOG_FILE: Path = LOG_DIR / "reflected_responses.json"

LOG_DIR.mkdir(parents=True, exist_ok=True)
_write_lock = threading.Lock()


def rotate_if_big(path: Path, max_mb: int = 20) -> None:
    """–†–æ—Ç–∏—Ä—É–µ—Ç —Ñ–∞–π–ª, –µ—Å–ª–∏ –æ–Ω –ø—Ä–µ–≤—ã—à–∞–µ—Ç max_mb –º–µ–≥–∞–±–∞–π—Ç."""
    try:
        if not path.exists():
            return

        size = path.stat().st_size
        if size <= max_mb * 1024 * 1024:
            return

        ts = datetime.datetime.utcnow().strftime("%Y%m%d_%H%M%S")
        backup = path.with_suffix(path.suffix + f".{ts}.bak")
        path.rename(backup)

        logging.info(f"[NDJSON] –õ–æ–≥ —Ä–æ—Ç–∏—Ä–æ–≤–∞–Ω: {path} ‚Üí {backup}")
    except Exception as e:
        logging.error(f"[NDJSON] –û—à–∏–±–∫–∞ —Ä–æ—Ç–∞—Ü–∏–∏ —Ñ–∞–π–ª–∞ {path}: {e}", exc_info=True)


def validate_result(result: Dict[str, Any]) -> bool:
    """–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã XSS-–∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞."""
    required = {"url", "category", "context"}
    missing = required - result.keys()

    if missing:
        logging.warning(f"[NDJSON] –ü—Ä–æ–ø—É—â–µ–Ω—ã –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è: {missing}")
        return False
    return True


def save_reflected_response(result: Dict[str, Any]) -> None:
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç XSS-–æ—Ç—Ä–∞–∂–µ–Ω–∏–µ –≤ NDJSON-—Ñ–∞–π–ª."""
    try:
        LOG_DIR.mkdir(parents=True, exist_ok=True)
        result.setdefault("_ts", datetime.datetime.utcnow().isoformat())

        if not validate_result(result):
            return

        rotate_if_big(LOG_FILE)

        with _write_lock:
            with LOG_FILE.open("a", encoding="utf-8") as f:
                f.write(json.dumps(result, ensure_ascii=False) + "\n")

        logging.info(f"[NDJSON] –°–æ—Ö—Ä–∞–Ω—ë–Ω –∞—Ä—Ç–µ—Ñ–∞–∫—Ç: {result.get('url')} [{result.get('category')}]")
    except Exception as e:
        logging.error(f"[NDJSON] –û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞: {e}", exc_info=True)


def load_reflected_responses(path: Path = LOG_FILE) -> List[Dict[str, Any]]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç NDJSON-—Ñ–∞–π–ª –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤."""
    results: List[Dict[str, Any]] = []

    if not path.exists():
        logging.warning(f"[NDJSON] –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {path}")
        return results

    try:
        with path.open(encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                try:
                    results.append(json.loads(line))
                except json.JSONDecodeError as e:
                    logging.warning(f"[NDJSON] –û—à–∏–±–∫–∞ JSON –≤ —Å—Ç—Ä–æ–∫–µ: {e}")
    except Exception as e:
        logging.error(f"[NDJSON] –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {path}: {e}", exc_info=True)

    logging.info(f"[NDJSON] –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(results)} –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –∏–∑ {path}")
    return results



if __name__ == "__main__":
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s [%(levelname)s] %(message)s",
        handlers=[
            logging.FileHandler("logs/xss_ndjson.log", encoding="utf-8"),
            logging.StreamHandler(),
        ],
    )

    responses = load_reflected_responses()
    print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(responses)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")

    for r in responses[:3]:
        print(r.get("url"), r.get("category"), r.get("context"))


